{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Fix Code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Replace 'pregnancy_data.csv' with the actual path to your dataset\n",
        "# Load the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/margaretham/MartenalCare/main/Maternal%20Health%20Risk%20Data%20Set%20(1).csv')\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "print(\"\\nMissing values in the dataset before handling:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Handle missing values\n",
        "# For numerical columns, fill with the median of each column\n",
        "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
        "\n",
        "# For categorical columns, fill with the mode (most frequent value) of the column\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
        "\n",
        "# Check again after filling missing values\n",
        "print(\"\\nMissing values in the dataset after handling:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Encode 'RiskLevel' (the target variable) to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "data['RiskLevel'] = label_encoder.fit_transform(data['RiskLevel'])  # Low = 0, Mid = 1, High = 2\n",
        "\n",
        "# Feature columns (excluding 'RiskLevel')\n",
        "X = data.drop(columns=['RiskLevel'])\n",
        "y = data['RiskLevel']\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Feature Scaling\n",
        "\n",
        "# Standardizing features (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshaping input data for LSTM (samples, timesteps, features)\n",
        "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))  # (samples, time_steps=1, features)\n",
        "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))  # (samples, time_steps=1, features)\n",
        "\n",
        "# Step 4: Build the Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), activation='relu'))\n",
        "model.add(LSTM(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))  # 3 classes: Low, Mid, High\n",
        "\n",
        "# Step 5: Compile and Train the Model\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping and learning rate scheduler\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = LearningRateScheduler(lambda epoch, lr: lr * 0.9 if epoch > 10 else lr)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test),\n",
        "                    callbacks=[early_stop, lr_scheduler])\n",
        "\n",
        "# Step 6: Predict with the model\n",
        "\n",
        "# Making predictions on the test data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Convert predictions from probabilities to class labels (0, 1, 2)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Step 7: Evaluate Model Performance\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n",
        "\n",
        "# Step 8: Predict on new input (example: User Input)\n",
        "\n",
        "# Ask for user input\n",
        "print(\"\\nPlease enter the following details:\")\n",
        "\n",
        "# Get user inputs for the features (ensure to convert inputs to the correct type)\n",
        "age = float(input(\"Age: \"))\n",
        "systolic_bp = float(input(\"Systolic Blood Pressure (SystolicBP): \"))\n",
        "diastolic_bp = float(input(\"Diastolic Blood Pressure (DiastolicBP): \"))\n",
        "bs = float(input(\"Blood Sugar Level (BS): \"))\n",
        "body_temp = float(input(\"Body Temperature (BodyTemp °F): \"))\n",
        "heart_rate = float(input(\"Heart Rate (HeartRate): \"))\n",
        "\n",
        "# Create a 2D array for input features (single sample)\n",
        "input_data = np.array([[age, systolic_bp, diastolic_bp, bs, body_temp, heart_rate]])\n",
        "\n",
        "# Step 9: Scale the user input using the same scaler used for the training data\n",
        "input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "# Reshape the input for the LSTM model (samples, time_steps=1, features)\n",
        "input_data_scaled = input_data_scaled.reshape((input_data_scaled.shape[0], 1, input_data_scaled.shape[1]))\n",
        "\n",
        "# Step 10: Predict the class (RiskLevel) for the input data\n",
        "risk_level_pred = model.predict(input_data_scaled)\n",
        "\n",
        "# Convert prediction from probabilities to class labels\n",
        "predicted_class = np.argmax(risk_level_pred, axis=1)\n",
        "\n",
        "# Step 11: Display the predicted risk level\n",
        "predicted_risk = label_encoder.inverse_transform(predicted_class)\n",
        "print(f\"\\nPredicted Risk Level: {predicted_risk[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcRSpOs0MDza",
        "outputId": "38feb23b-bdb3-48af-a7b6-0b116e2b83fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset:\n",
            "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
            "0   25         130           80  15.0      98.0         86  high risk\n",
            "1   35         140           90  13.0      98.0         70  high risk\n",
            "2   29          90           70   8.0     100.0         80  high risk\n",
            "3   30         140           85   7.0      98.0         70  high risk\n",
            "4   35         120           60   6.1      98.0         76   low risk\n",
            "\n",
            "Missing values in the dataset before handling:\n",
            "Age            0\n",
            "SystolicBP     0\n",
            "DiastolicBP    0\n",
            "BS             0\n",
            "BodyTemp       0\n",
            "HeartRate      0\n",
            "RiskLevel      0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in the dataset after handling:\n",
            "Age            0\n",
            "SystolicBP     0\n",
            "DiastolicBP    0\n",
            "BS             0\n",
            "BodyTemp       0\n",
            "HeartRate      0\n",
            "RiskLevel      0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-5a0df3aa0023>:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[col].fillna(data[col].mode()[0], inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.4039 - loss: 1.0950 - val_accuracy: 0.4286 - val_loss: 1.0809 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5055 - loss: 1.0716 - val_accuracy: 0.5419 - val_loss: 1.0298 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5715 - loss: 0.9918 - val_accuracy: 0.5517 - val_loss: 0.9034 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5931 - loss: 0.8731 - val_accuracy: 0.5911 - val_loss: 0.8113 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6408 - loss: 0.8025 - val_accuracy: 0.6158 - val_loss: 0.7644 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6153 - loss: 0.8008 - val_accuracy: 0.6059 - val_loss: 0.7509 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.7855 - val_accuracy: 0.6256 - val_loss: 0.7393 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6761 - loss: 0.6867 - val_accuracy: 0.6650 - val_loss: 0.7210 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6958 - loss: 0.6936 - val_accuracy: 0.6650 - val_loss: 0.7175 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6914 - loss: 0.7202 - val_accuracy: 0.6897 - val_loss: 0.7160 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6851 - loss: 0.6922 - val_accuracy: 0.6946 - val_loss: 0.7031 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7012 - loss: 0.6859 - val_accuracy: 0.6946 - val_loss: 0.6983 - learning_rate: 9.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6919 - loss: 0.6797 - val_accuracy: 0.6897 - val_loss: 0.6976 - learning_rate: 8.1000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7161 - loss: 0.6485 - val_accuracy: 0.6897 - val_loss: 0.6951 - learning_rate: 7.2900e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7231 - loss: 0.6374 - val_accuracy: 0.6897 - val_loss: 0.6874 - learning_rate: 6.5610e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6972 - loss: 0.6539 - val_accuracy: 0.6847 - val_loss: 0.6866 - learning_rate: 5.9049e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6932 - loss: 0.6670 - val_accuracy: 0.6897 - val_loss: 0.6867 - learning_rate: 5.3144e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7009 - loss: 0.6587 - val_accuracy: 0.6897 - val_loss: 0.6865 - learning_rate: 4.7830e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7005 - loss: 0.6554 - val_accuracy: 0.6847 - val_loss: 0.6836 - learning_rate: 4.3047e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6868 - loss: 0.6652 - val_accuracy: 0.6847 - val_loss: 0.6816 - learning_rate: 3.8742e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6748 - loss: 0.6884 - val_accuracy: 0.6847 - val_loss: 0.6797 - learning_rate: 3.4868e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7127 - loss: 0.6191 - val_accuracy: 0.6847 - val_loss: 0.6804 - learning_rate: 3.1381e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6813 - loss: 0.6457 - val_accuracy: 0.6897 - val_loss: 0.6813 - learning_rate: 2.8243e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6816 - loss: 0.6669 - val_accuracy: 0.6897 - val_loss: 0.6783 - learning_rate: 2.5419e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 0.6282 - val_accuracy: 0.6897 - val_loss: 0.6782 - learning_rate: 2.2877e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7019 - loss: 0.6323 - val_accuracy: 0.6847 - val_loss: 0.6804 - learning_rate: 2.0589e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6793 - loss: 0.6574 - val_accuracy: 0.6847 - val_loss: 0.6794 - learning_rate: 1.8530e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7080 - loss: 0.6365 - val_accuracy: 0.6897 - val_loss: 0.6784 - learning_rate: 1.6677e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7082 - loss: 0.6477 - val_accuracy: 0.6897 - val_loss: 0.6786 - learning_rate: 1.5009e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7080 - loss: 0.6192 - val_accuracy: 0.6897 - val_loss: 0.6785 - learning_rate: 1.3509e-04\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high risk       0.80      0.91      0.85        47\n",
            "    low risk       0.61      0.88      0.72        80\n",
            "    mid risk       0.77      0.36      0.49        76\n",
            "\n",
            "    accuracy                           0.69       203\n",
            "   macro avg       0.73      0.72      0.69       203\n",
            "weighted avg       0.72      0.69      0.66       203\n",
            "\n",
            "\n",
            "Please enter the following details:\n",
            "Age: 34\n",
            "Systolic Blood Pressure (SystolicBP): 120\n",
            "Diastolic Blood Pressure (DiastolicBP): 80\n",
            "Blood Sugar Level (BS): 7\n",
            "Body Temperature (BodyTemp °F): 80\n",
            "Heart Rate (HeartRate): 100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\n",
            "Predicted Risk Level: low risk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}